TODO: Reflect on what you learned this week and what is still unclear.

# Week 6

> Journal entry: Had a rest this week...

jokes

UNSW trolled me.

We were 4 weeks behind for a course (which will remain unamed), and the reason we were 4 weeks behind is due to the administration and organisation of said course. coughcoughcode1240coughcough. Thus this week was spent cramming 4 weeks worth of deliverables into 1 week.

I love uni.

# Supplementary Readings

> Missed a few readings back in the last couple of weeks, so I thought I would catch up with some.

> The two texts:

- Davis, D. (2015). Why Architects Canâ€™t Be Automated.
- Doherty, B. (2015). Architects getting automated?

Both were an interesting read, made more so that we touched on this topic during Nicole's class last term. I always find it fundamentally more interesting to read something, and then read another thing based on the first. It feels a bit akin to watching a YouTube video, then reading the comments, whereas if you watch the video and there's no comments, it's a tad less interesting. Or maybe I'm just basic xd

In Davis' text, he mentions that the probability of architects getting automated is very low, giving the audience more of an interesting read, than an existential crisis that their jobs may be taken over in the near future. Ben in his article, seems to have read between the lines and caught the fact that Davis' is cutting it as close as he could, without startling the audience. I do share an opinion that while jobs like accounting, banking etc that require number crunching with little need for creative input, will be replaced by automation, I share a similar hope (the world would be a lot spicier if AI were able to touch on a creative essence similar to how our creativeness is developed through schema) or opinion that while the creativeness is a current problem for AI, it's not am impossible one. One technological singularity which no one expects, could easily breach the creative differential.

While I am a bit allergic to mathematical notation (i skipped the maths parts in the reading, for I only had 2 surviving brain cells), I did pick up on the part where Ben mentioned that he doesn't see anything special in human's neural machinery. I'm not very good at this stuff, nor am I good thinker, but my thought is that - while I agree that the neural machinery in most humans can be replicated eventually by AI, there are some beings which have neural machinery that cannot be copied, replicated or developed.

If I could give an anology to explain this, it would be comparing someone who works hard but has little talent, and someone who works hard and has talent in that area. It's very apparent in the design world, that if you work hard, you can reach an acceptable or even good standard, but you'll never be as good as someone with talent. I understand this, as I often have to put in more hours into learning things but never reach the standard where people with talent can, no matter how much work is put in.

I digress, but going back to the neural machinery topic, I think that while the neural machinery of the generalised population that "works hard" will be reached by AI, I'm extremely curious to see how they (AI) will tackle the creative gap between something that is done through hard work, and something that is done through pure talent.
